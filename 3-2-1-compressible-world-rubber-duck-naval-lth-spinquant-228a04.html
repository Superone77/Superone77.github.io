<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üìñ&lt;/text&gt;&lt;/svg&gt;">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>3-2-1: Compressible World, Rubber Duck, Naval, LTH, SpinQuant&nbsp;|&nbsp;Vinci‚Äôs Garden</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="3-2-1: Compressible World, Rubber Duck, Naval, LTH, SpinQuant">
  
    <meta name="description" content="I believe world is compressible. For example, the release of Stable Diffusion in 2022 felt as if the entire history of human visual art had been compressed into a model file just over 2GB in size.">
    <meta property="og:description" content="I believe world is compressible. For example, the release of Stable Diffusion in 2022 felt as if the entire history of human visual art had been compressed into a model file just over 2GB in size.">
  
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üìñ&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üòÄ&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>About Vinci</span>
        </div>
      </a>
    
  
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
    <h1 class="Header__Title">3-2-1: Compressible World, Rubber Duck, Naval, LTH, SpinQuant</h1>
    
      <div class="DateTagBar">
        
          <span class="DateTagBar__Item DateTagBar__Date">Posted on Mon, Jul 7, 2025</span>
        
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--red">
            <a href="tag/3-2-1.html">3-2-1</a>
          </span>
        
      </div>
    
  </header>
  <article id="https://www.notion.so/228a0479abc780ef9cc2cc29104a1b5a" class="PageRoot"><div id="https://www.notion.so/228a0479abc78046b9aad23bc4c98b13" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Date">@2025/07/07</span></span><span class="SemanticString"> </span></span></p></div><blockquote id="https://www.notion.so/228a0479abc78054b8d3db8aecccf57d" class="ColorfulBlock ColorfulBlock--ColorDefault Quote"><span class="SemanticStringArray"><span class="SemanticString">3-2-1 Monday by Vinci Yang</span></span></blockquote><h2 id="https://www.notion.so/228a0479abc78042b1d1d399ddd693c2" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/228a0479abc78042b1d1d399ddd693c2"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3 Small Things</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/228a0479abc78043b54bc551b80fa2e9" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">I believe world is compressible. For example, the release of Stable Diffusion in 2022 felt as if the entire history of human visual art had been compressed into a model file just over 2GB in size.</span></span></li><li id="https://www.notion.so/228a0479abc780fb8fcce55da33b2c4f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">In engineering circles, there‚Äôs a term called ‚ÄúRubber Ducking‚Äù‚Äîbefore asking a senior colleague, you first explain your problem to a rubber duck. Often, you‚Äôll find the answer yourself in the process. BTW, currently, you have many AI as your powerful rubber duck.</span></span></li><li id="https://www.notion.so/228a0479abc7808f978afc40cc524221" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">2 words from Naval‚Äôs: ‚ÄúThe difference between successful and unsuccessful people lies in the intensity of their desire for success. Successful individuals are deeply driven - they are willing to start over, again and again, whether in their careers, relationships, or any other aspect of life.‚Äù , and ‚ÄúIf you ask yourself, what advice would you give yourself ten years ago? Almost without exception, the advice you would give your younger self is exactly what you need to hear right now.‚Äù</span></span></li></ul><div id="https://www.notion.so/228a0479abc780f48e0ac943b651543f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/228a0479abc780eea112c9dabb0c3279" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/228a0479abc780c4a063f5735c20149a" class="Divider"></div><h2 id="https://www.notion.so/228a0479abc7801885cfd699a057e544" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/228a0479abc7801885cfd699a057e544"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">2 Paper Introduction</span></span></h2><h3 id="https://www.notion.so/228a0479abc780889826e4d9f7cb8e25" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/228a0479abc780889826e4d9f7cb8e25"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">I. </span></span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</span></strong></span></span></h3><div id="https://www.notion.so/228a0479abc7806da37fc751bc14d75a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">The Lottery Ticket Hypothesis </strong></span><span class="SemanticString">posits that within a randomly-initialized dense network lies a highly sparse ‚Äúwinning ticket‚Äù subnetwork which, when reset to its original weights and trained in isolation, reaches comparable accuracy in roughly the same number of iterations. Using an iterative loop of magnitude pruning, weight rewinding, and retraining on MNIST and CIFAR-10, the authors find that keeping only about 10‚Äì20 % of parameters can match‚Äîor even surpass‚Äîthe full model, and that the original initialization, not just the topology, is critical. This reframes pruning as a training-aware search for effective models rather than a post-hoc compression trick, highlighting the synergy of sparse structure and lucky initialization. </span></span></p></div><div id="https://www.notion.so/228a0479abc780119addd93abe8c36c6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">In my view, this closed-loop perspective redirects pruning research toward discovering truly capable models, offering a fresh lens on optimization dynamics and capacity.</span></span></p></div><div id="https://www.notion.so/228a0479abc780cf8702daf9bc448426" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/228a0479abc780349c5ec511561a9149" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/228a0479abc780349c5ec511561a9149"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">II. SpinQuant: LLM quantization with learned rotations</span></strong></span></span></h3><div id="https://www.notion.so/228a0479abc78027b4d0ce45fbebc770" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">SpinQuant</strong></span><span class="SemanticString"> turns rotation into a learnable pre-conditioning step for post-training LLM quantization: it trains a pair of orthogonal matrices (via Cayley-SGD on the Stiefel manifold) that ‚Äúspin‚Äù weights and activations so their outliers vanish, then folds the rotations back so inference still runs at the original cost. With just this tweak Llama-2/3 models hold within ~3 pp of full-precision at 4-bit W-A-KV and beat previous PTQ/QAT baselines by wide margins; an optional fast-Hadamard pass pushes to KV-4 with only a single-digit % latency bump. </span></span></p></div><div id="https://www.notion.so/228a0479abc7801e8293d230351e402c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I like the work because it turns the ad-hoc ‚Äúrandom rotation‚Äù trick into a principled, differentiable, zero-overhead hack that slots cleanly alongside GPTQ/AWQ. The open question is how the calibration overhead and learned rotations scale for truly massive (&gt;1 T-param) or highly structured sparse models.

</span></span></p></div><h2 id="https://www.notion.so/228a0479abc78054b6d8c3559ed7f27a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/228a0479abc78054b6d8c3559ed7f27a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1 Question From Me</span></span></h2><div id="https://www.notion.so/228a0479abc780f0823defc234587bb1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">How to find a great learning rate and weight decay for your optimizer as efficient as possible?</span></span></p></div><div id="https://www.notion.so/228a0479abc780c49383c9a7f69f0340" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/228a0479abc78054b98fc53d7c25a195" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Until Next week,</span></span></p></div><div id="https://www.notion.so/228a0479abc7805caeaadaed0d76574b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/228a0479abc7805cb908c3340f2ccc0d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Vinci Yang</span></span></p></div></article>
  <footer class="Footer">
  <div>&copy; Vinci‚Äôs Garden 2024</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>

</body>

</html>